{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statistics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('House_Price.csv')\n",
    "y = df.price\n",
    "#print(y)\n",
    "x = df\n",
    "x = x.drop('price', axis=1)\n",
    "#print(x)\n",
    "\n",
    "trainSplit = int(len(y)*0.8)\n",
    "trainY = y[0:trainSplit]\n",
    "trainX = x[0:trainSplit]\n",
    "testY = y[trainSplit:]\n",
    "testX = x[trainSplit:]\n",
    "\n",
    "\n",
    "trainX = [2,3,5,6,10,12,15,16,17,18,25,26,27,28,29,30,35,36,40]\n",
    "trainY = [0,0,0,0,5,20,100,100,100,100,60,55,53,50,45,10,0,0,0]\n",
    "plt.scatter(trainX,trainY)\n",
    "plt.show()\n",
    "#print(len(trainY))\n",
    "#print(len(trainX))\n",
    "class Node():\n",
    "    def __init__(self, **kwargs):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.decision = None\n",
    "        if 'nodeValue' in kwargs:            \n",
    "            self.nodeValue = kwargs['nodeValue']\n",
    "        else:\n",
    "            self.nodeValue = None\n",
    "\n",
    "    #def setA(self, decision):\n",
    "    #    self.decision = decision\n",
    "\n",
    "def resError(y,prediction):\n",
    "    error = 0\n",
    "    for i in y:\n",
    "        error += (i-prediction)**2\n",
    "    return error\n",
    "\n",
    "def build(x,y, threshold):\n",
    "    leaf = Node()\n",
    "    if len(y) < 4:\n",
    "        #print(y)\n",
    "        setattr(leaf,'nodeValue',statistics.mean(y))\n",
    "        #leaf.nodeValue = statistics.mean(y)\n",
    "        return leaf\n",
    "    \n",
    "    average = []\n",
    "    error = []\n",
    "\n",
    "    for i in range(len(y)-1):\n",
    "        average.append((x[i]+x[i+1])/2)\n",
    "        error.append(resError(y,average[i]))\n",
    "\n",
    "    minErrorIdx = error.index(min(error))\n",
    "    #print(minErrorIdx)\n",
    "    #print(len(y))\n",
    "    #print(x[minErrorIdx:],y[minErrorIdx:])\n",
    "    #print(x[:minErrorIdx],y[:minErrorIdx])\n",
    "    #print(average)\n",
    "    setattr(leaf,'decision',x[minErrorIdx])\n",
    "    if minErrorIdx > 0:\n",
    "        setattr(leaf,'left',build(x[:minErrorIdx],y[:minErrorIdx],threshold))\n",
    "    else:\n",
    "        setattr(leaf,'left',Node(nodeValue=y[0]))\n",
    "    if minErrorIdx < len(y):\n",
    "        setattr(leaf,'right',build(x[minErrorIdx+1:],y[minErrorIdx+1:],threshold))\n",
    "    else:\n",
    "        setattr(leaf,'right',Node(nodeValue=y[0]))\n",
    "    #plt.scatter(np.linspace(0,len(error)+1,num=len(error)),error)\n",
    "    #plt.show()\n",
    "    return leaf\n",
    "\n",
    "def predict(node, prediction):\n",
    "    if node.decision == None:\n",
    "        #print(\"set\")\n",
    "        return node.nodeValue\n",
    "    elif prediction > node.decision:\n",
    "        if node.right:\n",
    "            #print(\"right\")\n",
    "            return predict(node.right, prediction)\n",
    "        else:\n",
    "            return node.nodeValue\n",
    "    else:\n",
    "        if node.left != None:\n",
    "            #print(\"left\")\n",
    "            return predict(node.left, prediction)\n",
    "        else:\n",
    "            return node.nodeValue\n",
    "\n",
    "root = build(trainX,trainY,30)\n",
    "\n",
    "print(predict(root,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statistics\n",
    "\n",
    "\n",
    "df = pd.read_csv('House_Price.csv')\n",
    "df = df.drop('airport', axis=1)\n",
    "df = df.drop('waterbody', axis=1)\n",
    "df = df.drop('bus_ter', axis=1)\n",
    "df = df.dropna()\n",
    "y = df.price\n",
    "#print(y)\n",
    "x = df\n",
    "x = x.drop('price', axis=1)\n",
    "#print(x)\n",
    "\n",
    "trainSplit = int(len(y)*0.8)\n",
    "trainY = y[0:trainSplit]\n",
    "trainX = x[0:trainSplit]\n",
    "testY = y[trainSplit:]\n",
    "testX = x[trainSplit:]\n",
    "\n",
    "#trainX = [2,3,5,6,10,12,15,16,17,18,25,26,27,28,29,30,35,36,40]\n",
    "#trainY = [0,0,0,0,5,20,100,100,100,100,60,55,53,50,45,10,0,0,0]\n",
    "#plt.scatter(trainX,trainY)\n",
    "#plt.show()\n",
    "#print(len(trainY))\n",
    "#print(len(trainX))\n",
    "class Node():\n",
    "    def __init__(self, **kwargs):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.decision = None\n",
    "        self.attr = None\n",
    "        if 'nodeValue' in kwargs:            \n",
    "            self.nodeValue = kwargs['nodeValue']\n",
    "        else:\n",
    "            self.nodeValue = None\n",
    "\n",
    "    #def setA(self, decision):\n",
    "    #    self.decision = decision\n",
    "\n",
    "def resError(y,prediction):\n",
    "    error = 0\n",
    "    for i in y:\n",
    "        error += (i-prediction)**2\n",
    "    return error/len(y)\n",
    "\n",
    "def getMin(x,y):\n",
    "    average = []\n",
    "    error = []\n",
    "    #print(x)\n",
    "    x, y = zip(*sorted(zip(x, y)))\n",
    "    #for i in x:\n",
    "    #    print(i)\n",
    "    #print(\"NEXT\")\n",
    "    for i in range(len(y)-1):\n",
    "        average = (y[i]+y[i+1])/2\n",
    "        error.append(resError(y,average))\n",
    "        #error.append(mean_squared_error(y,average))\n",
    "    minErrorIdx = error.index(min(error))\n",
    "    return minErrorIdx, min(error)\n",
    "\n",
    "def build(x,y, threshold):\n",
    "    leaf = Node()\n",
    "    x = x.reset_index(drop=True)\n",
    "    y = y.reset_index(drop=True)\n",
    "    if len(y) < threshold*2:\n",
    "        #print(y)\n",
    "        setattr(leaf,'nodeValue',statistics.mean(y))\n",
    "        #print(\"remained points in leaf\",len(y))\n",
    "        #leaf.nodeValue = statistics.mean(y)\n",
    "        return leaf\n",
    "    \n",
    "    idxList = []\n",
    "    errorList = []\n",
    "    nameList = []\n",
    "    \n",
    "    for i in range(x.shape[1]):\n",
    "        name = x.columns[i]\n",
    "        nameList.append(name)\n",
    "        minErrorIdx, error = getMin(x.loc[:,name],y)\n",
    "        errorList.append(error)\n",
    "        idxList.append(minErrorIdx)\n",
    "\n",
    "    #print(errorList)\n",
    "    #print(idxList)\n",
    "    #print(nameList)\n",
    "    minValue = 90000\n",
    "    tempIdx = 0\n",
    "    median = len(y)/2\n",
    "    for i in range(0,len(errorList)):\n",
    "        if errorList[i] < minValue:\n",
    "            minValue = errorList[i]\n",
    "            tempIdx = idxList[i]\n",
    "        if errorList == minValue:\n",
    "            if abs(idxList[i]-median) < abs(tempIdx-median):\n",
    "                minValue = errorList[i]\n",
    "                tempIdx = idxList[i]\n",
    "\n",
    "    minErrorIdx = tempIdx\n",
    "    #minErrorIdx = idxList[errorList.index(min(errorList))]\n",
    "    #name = nameList[errorList.index(min(errorList))]\n",
    "    name = nameList[idxList.index(minErrorIdx)]\n",
    "    test =  x.join(y)\n",
    "    test = test.sort_values(by=[name], ascending=True)\n",
    "    #print(test)\n",
    "    y = test.price\n",
    "    #print(y)\n",
    "    x = test\n",
    "    x = x.drop('price', axis=1)\n",
    "\n",
    "    #print(\"i have elements in x\",x.shape[0],\"and now i want to take out one on idx\",minErrorIdx)\n",
    "    #print(min(errorList))\n",
    "    #print(minErrorIdx)\n",
    "    #print(nameList[minErrorIdx])\n",
    "    #print(minErrorIdx)\n",
    "    #print(len(y))\n",
    "    #print(x[minErrorIdx:],y[minErrorIdx:])\n",
    "    #print(x[:minErrorIdx],y[:minErrorIdx])\n",
    "    #print(average)\n",
    "    setattr(leaf,'attr',name)\n",
    "    #print(\"THIS SOME BULL\",x.loc[:,name][minErrorIdx])\n",
    "    #print(x[minErrorIdx+1:])\n",
    "    #print(\"my name is \",nameList[minErrorIdx],\"and i want index\",minErrorIdx,\"from array of names\",nameList)\n",
    "    #print(x.loc[:,name])\n",
    "    #print(\"Do i crash here ?\")\n",
    "    setattr(leaf,'decision',x.loc[:,name][minErrorIdx])\n",
    "    #print(error)\n",
    "    if minErrorIdx > threshold:\n",
    "        #print(\"My error idx\",minErrorIdx)\n",
    "        #print(\"lenght of my x\",x.shape[1])\n",
    "        setattr(leaf,'left',build(x[:minErrorIdx-1],y[:minErrorIdx-1],threshold))\n",
    "    else:\n",
    "        #print(y[0])\n",
    "        #print(\"remained points in leaf\",len(y))\n",
    "        setattr(leaf,'left',Node(nodeValue=statistics.mean(y)))\n",
    "    #print(\"my len\", len(x), len(y))\n",
    "    if (x.shape[0]-minErrorIdx) > threshold :\n",
    "        #print(\"My error idx\",minErrorIdx)\n",
    "        #print(\"lenght of my x\",x.shape[1])\n",
    "        setattr(leaf,'right',build(x[minErrorIdx+1:],y[minErrorIdx+1:],threshold))\n",
    "    else:\n",
    "        #if len(y) < 1:\n",
    "        #print(\"kek\")\n",
    "        #print(\"remained points in leaf\",len(y))\n",
    "        setattr(leaf,'right',Node(nodeValue=statistics.mean(y)))\n",
    "        #else:\n",
    "        #    setattr(leaf,'nodeValue',statistics.mean(y))\n",
    "    #plt.scatter(np.linspace(0,len(error)+1,num=len(error)),error)\n",
    "    #plt.show()\n",
    "    return leaf\n",
    "\n",
    "#print(trainX)\n",
    "#print(trainY)\n",
    "root = build(trainX,trainY,20)\n",
    "#print(predict(root,10))\n",
    "#print(trainX.shape[1])\n",
    "#for i in range(trainX.shape[0]):\n",
    "#    name = trainX.columns[i]\n",
    "#    print(trainX.loc[:,name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawTree(ax,tree,depth,x):\n",
    "    ax.plot(x,depth,'ro')\n",
    "    ax.annotate(tree.attr, (x,depth))\n",
    "    ax.annotate(tree.decision, (x,depth+0.2))\n",
    "    ax.annotate(tree.nodeValue, (x,depth))\n",
    "    #if tree.nodeValue:\n",
    "       # print(tree.nodeValue,depth)\n",
    "    dist = 10\n",
    "    if tree.left:\n",
    "        drawTree(ax,tree.left,depth+1,x-dist)\n",
    "    if tree.right:\n",
    "        drawTree(ax,tree.right,depth+1,x+dist)\n",
    "\n",
    "\n",
    "#ax = plt.subplot()\n",
    "#drawTree(ax,root,0,0)\n",
    "#print(testX.iloc[1])\n",
    "#predicted = predict(root,testX.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.325134158940266\n",
      "4132.5134158940255\n",
      "[17.507142857142856, 15.808571428571428, 15.204166666666667, 26.9265625, 15.808571428571428, 15.808571428571428, 26.9265625, 17.507142857142856, 17.507142857142856, 15.808571428571428, 15.808571428571428, 17.507142857142856, 17.507142857142856, 17.507142857142856, 15.808571428571428, 15.808571428571428, 17.507142857142856, 26.9265625, 17.507142857142856, 15.808571428571428, 15.808571428571428, 17.507142857142856, 26.9265625, 17.507142857142856, 17.507142857142856, 17.507142857142856, 15.808571428571428, 26.9265625, 15.808571428571428, 15.808571428571428, 17.507142857142856, 15.808571428571428, 17.507142857142856, 17.507142857142856, 17.507142857142856, 15.808571428571428, 17.507142857142856, 15.808571428571428, 15.808571428571428, 15.808571428571428, 15.808571428571428, 17.507142857142856, 17.507142857142856, 17.507142857142856, 15.808571428571428, 17.507142857142856, 15.808571428571428, 15.808571428571428, 15.808571428571428, 15.808571428571428, 15.808571428571428, 15.808571428571428, 17.507142857142856, 15.808571428571428, 15.808571428571428, 17.507142857142856, 26.9265625, 26.9265625, 26.9265625, 26.9265625, 26.9265625, 17.507142857142856, 17.507142857142856, 15.808571428571428, 15.808571428571428, 15.808571428571428, 26.9265625, 26.9265625, 26.9265625, 17.507142857142856, 17.507142857142856, 15.808571428571428, 17.507142857142856, 15.808571428571428, 26.9265625, 26.9265625, 26.9265625, 26.9265625, 26.9265625, 26.9265625, 26.9265625, 17.507142857142856, 26.9265625, 15.808571428571428, 16.34923076923077, 16.34923076923077, 15.808571428571428, 26.9265625, 32.75, 32.75, 32.75, 32.75, 32.75, 32.75, 32.75, 26.9265625, 26.9265625, 26.9265625, 26.9265625, 26.9265625]\n"
     ]
    }
   ],
   "source": [
    "def predict(node, prediction):\n",
    "    \n",
    "    if node.decision == None:\n",
    "        #print(\"set\")\n",
    "        return node.nodeValue\n",
    "    else:\n",
    "        attr = node.attr\n",
    "        name = ''\n",
    "        for i in range(0,trainX.shape[1]):\n",
    "            name = trainX.columns[i]\n",
    "            if name == attr:\n",
    "                #print(\"my name is\",attr)\n",
    "                predValue = prediction.loc[name]\n",
    "                break\n",
    "        \n",
    "        #print(\"chosen attr\", name,\"with value\", predValue)\n",
    "        if predValue > node.decision:\n",
    "            if node.right:\n",
    "                #print(\"The value\",predValue,\"is bigger than\",node.decision)\n",
    "                #print(\"right\")\n",
    "                return predict(node.right, prediction)\n",
    "            else:\n",
    "                return node.nodeValue\n",
    "        else:\n",
    "            if node.left != None:\n",
    "                #print(\"The value\",predValue,\"is smaller than\",node.decision)\n",
    "                #print(\"left\")\n",
    "                return predict(node.left, prediction)\n",
    "            else:\n",
    "                return node.nodeValue\n",
    "error = 0\n",
    "resArr = []\n",
    "#print(root.attr)\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "for i in range(0,testX.shape[0]):\n",
    "    predicted = predict(root,testX.iloc[i])\n",
    "    resArr.append(predicted)\n",
    "    error += (testY.iloc[i] - predicted)**2\n",
    "    #print(testY.iloc[i])\n",
    "    #print(testY.iloc[i]-predicted)\n",
    "    #print(predict(root,testX.iloc[3]))\n",
    "    #print(testY.iloc[3])\n",
    "#print(root.left.right.right.right.nodeValue)\n",
    "print(mean_squared_error(testY,resArr))\n",
    "print(error)\n",
    "#print(testY)\n",
    "print(resArr)\n",
    "depth = 0\n",
    "def walk(tree, depth):\n",
    "    #if tree.attr != None: print(tree.nodeValue,depth)\n",
    "    if tree.right != None:\n",
    "        walk(tree.right,depth+1)\n",
    "    if tree.left != None:\n",
    "        walk(tree.left,depth+1)\n",
    "    #print(\"I AM ON DEPTH\",depth)\n",
    "    #print(tree.nodeValue)\n",
    "walk(root,depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.153084128659053\n",
      "[10.98571429 10.98571429 10.98571429 20.74814815 10.98571429 29.212\n",
      " 20.74814815 10.98571429 10.98571429 10.98571429 10.98571429 10.98571429\n",
      " 10.98571429 10.98571429 29.212      10.98571429 10.98571429 20.74814815\n",
      " 10.98571429 10.98571429 10.98571429 10.98571429 10.98571429 10.98571429\n",
      " 10.98571429 10.98571429 29.212      20.74814815 15.3        10.98571429\n",
      " 10.98571429 10.98571429 10.98571429 10.98571429 10.98571429 10.98571429\n",
      " 10.98571429 10.98571429 10.98571429 10.98571429 10.98571429 10.98571429\n",
      " 10.98571429 10.98571429 10.98571429 10.98571429 15.3        15.3\n",
      " 29.212      10.98571429 15.3        15.3        10.98571429 10.98571429\n",
      " 10.98571429 15.3        15.3        20.74814815 20.74814815 22.485\n",
      " 22.485      15.3        15.3        10.98571429 10.98571429 15.3\n",
      " 22.485      22.485      29.212      10.98571429 10.98571429 15.3\n",
      " 10.98571429 10.98571429 20.74814815 22.485      26.90714286 29.212\n",
      " 19.14       19.14       20.355      10.98571429 22.485      20.44347826\n",
      " 17.41904762 17.41904762 17.41904762 20.74814815 20.74814815 20.74814815\n",
      " 20.44347826 22.485      20.74814815 20.44347826 20.74814815 30.3875\n",
      " 30.3875     29.212      30.3875     30.3875    ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "#print(cross_val_score(model, testX, testY, cv=10))\n",
    "model = DecisionTreeRegressor(random_state=0,min_samples_leaf = 20)\n",
    "model.fit(trainX,trainY)\n",
    "res = model.predict(testX)\n",
    "err = 0\n",
    "#print(res)\n",
    "for i in range(len(res)):     \n",
    "    err += (testY.iloc[i] - res[i])**2\n",
    "\n",
    "print(mean_squared_error(testY,res))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 fold mean sqared error on our model 76.16010970638641\n",
      "10 fold mean sqared error on scikit model 30.648700247406037\n"
     ]
    }
   ],
   "source": [
    "#setattr(leaf,'right',build(x[minErrorIdx+1:],y[minErrorIdx+1:],threshold))\n",
    "def k_fold(X, y, fold):\n",
    "    score_mean_squared = 0\n",
    "    #score_r2 = 0\n",
    "    counter = 0\n",
    "    step_size = int(X.shape[0]/fold)\n",
    "    #print(step_size)\n",
    "    for i in range(0,X.shape[0]-step_size,step_size):\n",
    "        testX = X[i:i+step_size]        \n",
    "        testY = y[i:i+step_size]    \n",
    "        trainX = X[0:i]\n",
    "        trainX = trainX.append(X[i+step_size+1:], ignore_index=True)        \n",
    "        #trainX = np.append(trainX,X[i+step_size+1:], axis=0)\n",
    "        #print(len(trainX))\n",
    "        trainY = y[0:i]\n",
    "        #trainY = np.append(trainY,y[i+step_size+1:], axis=0)\n",
    "        trainY = trainY.append(y[i+step_size+1:], ignore_index=True)\n",
    "        root = build(trainX, trainY, 20)\n",
    "        resArr = []\n",
    "        for j in range(0,testX.shape[0]):\n",
    "            predicted = predict(root,testX.iloc[j])\n",
    "            resArr.append(predicted)\n",
    "            #score_mean_squared += (testY.iloc[i] - predicted)**2\n",
    "        score_mean_squared += mean_squared_error(testY,resArr)\n",
    "        #print(\"error on ours on\",i,\"itteration\",mean_squared_error(testY,resArr))\n",
    "        #model = DecisionTreeRegressor(random_state=0)\n",
    "        #model.fit(trainX,trainY)\n",
    "        \n",
    "        #y_pred_sclearn = predict(reg, testX)\n",
    "        #score_mean_squared += mean_squared_error(testY, 1)\n",
    "        #score_r2 = r2_score(testY, y_pred_sclearn)\n",
    "        counter += 1\n",
    "    return score_mean_squared/counter\n",
    "\n",
    "def k_fold_sci(X, y, fold):\n",
    "    score_mean_squared = 0\n",
    "    #score_r2 = 0\n",
    "    counter = 0\n",
    "    step_size = int(X.shape[0]/fold)\n",
    "    #print(step_size)\n",
    "    for i in range(0,X.shape[0]-step_size,step_size):\n",
    "        testX = X[i:i+step_size]        \n",
    "        testY = y[i:i+step_size]    \n",
    "        trainX = X[0:i]\n",
    "        trainX = trainX.append(X[i+step_size+1:], ignore_index=True)        \n",
    "        trainY = y[0:i]\n",
    "        trainY = trainY.append(y[i+step_size+1:], ignore_index=True)\n",
    "        model = DecisionTreeRegressor(random_state=0, min_samples_leaf=20, min_samples_split=40)\n",
    "        model.fit(trainX,trainY)\n",
    "        res = model.predict(testX)\n",
    "        #print(\"lenght res\",len(res),\"len test\",len(testY))\n",
    "        score_mean_squared += mean_squared_error(testY, res)\n",
    "        #print(\"Error on scikit on\",i,\"itteration\",mean_squared_error(testY,res))\n",
    "        counter += 1\n",
    "    return score_mean_squared/counter\n",
    "\n",
    "\n",
    "print(\"10 fold mean sqared error on our model\",k_fold(x,y,10))\n",
    "print(\"10 fold mean sqared error on scikit model\",k_fold_sci(x,y,10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
